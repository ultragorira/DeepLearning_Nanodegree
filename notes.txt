14012022

Concepts reviewed:

Training and Testing Sets = Training model and use Testing to verify how good model performs. You never use testing data to train the model. 
Overfitting and Underfitting => Underfitting means the model is too simplistic and tend to oversimplifed the problem. Called also error due to bias. 
Overfittin is the opposite. Model is way too specific and performs pefectly on training set but on testing it wil fail as it cannot generalize that well. Called also error due to variance. 
Early Stopping => We do gradient descent until the testing error stops and starts increasing. That is the right spot and called early stopping. 
Regularization (L1 and L2) => T heproblem is that large coefficients are leading to it.We want to penalize in our error function large weights by either having a sum of the absolute values of the weights multiplied by lambda or the sum of the squares mulitplied by lambda. 
The first approach is called L1 Regularization. L1 tends to result in sparse vectors means that small weights tend to go to zero. Also this is good if we want to reduce the number of weights and have a small set. For feature selection is good because we can choose the most important ones and turn the rest to zero.
The second approach is called L2 Regularization and it is good for training purposes. 
L2 does not favor sparse vectors since it tries to mantain all the weights homogeneously small. 

Dropout => a parameter given when training. e.g. 0.2 means 20% of the nodes will be turned off at each epoch. Some nodes may be never turned off and some more than others but in average each node will be turned off equally.

15012022

Local Minima => When there are multiple low points and gradient descent may end up not at the lowest point but the lowest local point.
To avoid this we can do a random restart from different positions and do gradient descent from all of them. 
Momentum => Another way to avoid local minima. The general idea is that the step to take will be an average of previous steps. Previous step multiplied by 1, previous one by Beta, previous one By Beta squared etc.. 
Vanish gradient problem => The sigmoid function gets pretty flat on the sides, so when calculating the derivatives at a point fat to right or left, the derivative is almost zero. 
This is a problem because the derivative is what tells you where to move towards and it would be very tiny steps.

Hyperbolic Tangent Function => Another activation function. e^x - e^-x/e^x+ e^x.
The values returned are between -1 and 1. 

ReLU => Rectified Linear Unit. Simple activation function. It return x if x is positive, if x is negative returns 0. ReLU is often used instead of Sigmoid. 

Stochastic gradient descent => If the data is well-distributed we can subset the data and run each subset throught the network, calculate the error and backpropagate. Then you repeat for next subset. 
Each step (epoch) may be less accurate than running once with all the data but in practice it is better to take a bunch of slightly inaccurate steps than take only one good one. 

Learning Rate => If learning rate is too big, you take too big steps. Too low learning rate will lead to too slow model and training. 
As a rule of thumb if the model is not working, you should decrease the learning rate. 

19112022

Better initialization of the weights => In Sentiment Analysis prob 3, weights for the hidden layer to output were initialized as self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, (self.hidden_nodes, self.output_nodes))

However, there is a better way of doing it. Normally the weights when initialized should be set to be close to zero without being too small.
Good practice is to start the weights in the range of [-y, y] where y is 1/âˆšn where n is the number of inputs of the layer.


